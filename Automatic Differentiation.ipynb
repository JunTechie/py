{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reverse mode automatic differentiation.\n",
    "\n",
    "* Any function, no matter how complicated, is evaluated by performing a sequence of simple elementary operations (ops) that contain one or 2 argument at a time.\n",
    "* Ops with a single argument: trigonometric functions, exp, log\n",
    "* Ops with two arguments: *, +, -, /"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "**Example:** Let $f:\\mathbb{R}^3 \\rightarrow \\mathbb{R}$ be given by\n",
    "\n",
    "$$ f(x_1,x_2,x_3) = (x_1x_2 \\sin(x_3) + e^{x_1x_2})/x_3$$\n",
    "\n",
    "**Input Variables:** $x_1$, $x_2$, and $x_3$\n",
    "\n",
    "**Intermediate Variables:** $x_4 = x_1x_2\\;\\; $,  $x_5 = \\sin(x_3)$,  $x_6 = e^{x_4}$,  $x_7 = x_4x_5$,  and  $x_8 = x_6 + x_7$.\n",
    "\n",
    "**Output Variable:** $x_9 = x_8 / x_3$.\n",
    "![\"Reverse mode\"](./images/ReverseMode2.png)\n",
    "<!-- <img style=\"float: center;\" src=\"ReverseMode2.png\" width=\"1000\"> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* In reverse mode automatic differentiation, each node $x_i$ in the computational graph is associated with a scaler node $\\bar{x_i} = \\dfrac{\\partial f}{\\partial x_i}$.\n",
    "* Information about $\\dfrac{\\partial f}{\\partial x_i}$ is accumulated in $\\bar{x_i}$ during a reverse sweep.\n",
    "* In forward sweep, the values of nodes $x_i$ are calculated using input node values. The partials $\\dfrac{\\partial x_j}{\\partial x_i}$, where $x_j$ is a direct descendant of $x_i$ are assigned to the edges\n",
    "* Initialization: $\\bar{x_i} = 0$ for $i = 1, \\cdots, 8$ and set $\\bar{x_9} = \\dfrac{\\partial f}{\\partial x_9} = \\dfrac{\\partial x_9}{\\partial x_9} = 1$.\n",
    "* Chain Rule: $\\bar{x_i} = \\dfrac{\\partial f}{\\partial x_i} = \\sum_{j \\text{child of } i} \\dfrac{\\partial f}{\\partial x_j}\\dfrac{\\partial x_j}{\\partial x_i}$\n",
    "* Accumulation: $\\bar{x_i} +=  \\dfrac{\\partial f}{\\partial x_j}\\dfrac{\\partial x_j}{\\partial x_i}$.\n",
    "* The above is performed as soon as $\\dfrac{\\partial f}{\\partial x_j}$ becomes available.\n",
    "* Once computations have been received from all children of node $i$, we have $\\bar{x_i}$ and the node is declared finalized.\n",
    "* At this stage node $i$ is ready to contribute to the terms in the summation for each of its parents nodes.\n",
    "* The process is continued until all nodes are finalized.\n",
    "* Note that the flow of the computation in the graph is from children to parents during the backward sweep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Automatic differentiation in TensorFlow\n",
    "To differentiate automatically, TensorFlow needs to remember what operations happen in what order during the forward pass. Then, during the backward pass, TensorFlow traverses this list of operations in reverse order to compute gradients.\n",
    "\n",
    "### Gradient tapes\n",
    "TensorFlow provides the `tf.GradientTape` API for automatic differentiation; that is, computing the gradient of a computation with respect to some inputs, usually `tf.Variables`. TensorFlow \"records\" relevant operations executed inside the context of a `tf.GradientTape` onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using reverse mode differentiation.\n",
    "\n",
    "Here is a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-01 16:11:24.319283: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x = tf.Variable(3.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  y = x**2\n",
    "\n",
    "# dy = 2x * dx\n",
    "dy_dx = tape.gradient(y, x)\n",
    "dy_dx.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y =  5.977258756447682\n",
      "yp =  [10.68127797  5.34063898 -3.80524111]\n",
      "yp = ['10.6813', '5.3406', '-3.8052']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x = tf.Variable(np.array([1.0,2.0,np.pi/2.]), dtype = tf.float64)\n",
    "\n",
    "## Note: Use tf.sin not np.sin as TF will treat np.sin as a constant\n",
    "with tf.GradientTape() as t:\n",
    "    y = (x[0] * x[1] * tf.sin(x[2]) + tf.exp(x[0] * x[1])) / x[2]\n",
    "yp = t.gradient(y, x)\n",
    "\n",
    "print(\"y = \", y.numpy())\n",
    "print(\"yp = \", yp.numpy())\n",
    "\n",
    "yp_manual = [(4. / np.pi) * (1 + np.exp(2)), (2. / np.pi) * (1 + np.exp(2)), (-8. - 4. * np.exp(2)) / (np.pi ** 2)]\n",
    "print('yp =', ['{:0.4f}'.format(i) for i in yp_manual])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
